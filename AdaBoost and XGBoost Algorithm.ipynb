{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries here\n",
    "import numpy as np\n",
    "# from sklearn import linear_model\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read datasets\n",
    "diabetes_train = pd.read_csv(\"diabetes_train.csv\")\n",
    "diabetes_test = pd.read_csv(\"diabetes_test.csv\")\n",
    "X_train = diabetes_train.drop('Outcome',axis=1)\n",
    "Y_train = diabetes_train['Outcome']\n",
    "X_test = diabetes_test.drop('Outcome',axis=1)\n",
    "Y_test = diabetes_test['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(algorithm, grid_params, X_train, Y_train):\n",
    "    reg_model = GridSearchCV(algorithm, grid_params, cv=5, n_jobs=-1, verbose=1)\n",
    "    reg_model.fit(X_train, Y_train)\n",
    "    parameters = reg_model.best_params_\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  7.4min finished\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter Tuning\n",
    "AB_params ={'learning_rate' :[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "              'n_estimators':[50,100,150,200,250]}\n",
    "params = train_eval(AdaBoostClassifier(), AB_params, X_train, Y_train)\n",
    "print(params['learning_rate'])\n",
    "print(params['n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \t 0.7575757575757576\n",
      "Sensitivity: \t 0.9\n",
      "Specificity: \t 0.49382716049382713\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost Algorithm \n",
    "ab_model = AdaBoostClassifier(learning_rate=params['learning_rate'],n_estimators=params['n_estimators'])\n",
    "ab_model. fit(X_train, Y_train)\n",
    "y_pred = ab_model.predict(X_test)\n",
    "cm1 = confusion_matrix(Y_test,y_pred)\n",
    "Accuracy_adb = (cm1[0,0]+cm1[1,1])/(cm1[0,0]+cm1[1,0]+cm1[0,1]+cm1[1,1])\n",
    "Sensitivity_adb = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "Specificity_adb = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print(\"Accuracy: \\t\", Accuracy_adb)\n",
    "print(\"Sensitivity: \\t\",Sensitivity_adb )\n",
    "print(\"Specificity: \\t\",Specificity_adb )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \t 0.7575757575757576\n",
      "Sensitivity: \t 0.9\n",
      "Specificity: \t 0.49382716049382713\n"
     ]
    }
   ],
   "source": [
    "#XGBoost Algorithm \n",
    "XGB_model = XGBClassifier(learning_rate=params['learning_rate'],n_estimators=params['n_estimators'])\n",
    "XGB_model.fit(X_train, Y_train)\n",
    "y_pred_xgb = ab_model.predict(X_test)\n",
    "cm2 = confusion_matrix(Y_test,y_pred_xgb)\n",
    "Accuracy_xgb = (cm2[0,0]+cm2[1,1])/(cm2[0,0]+cm2[1,0]+cm2[0,1]+cm2[1,1])\n",
    "Sensitivity_xgb = cm2[0,0]/(cm2[0,0]+cm2[0,1])\n",
    "Specificity_xgb = cm2[1,1]/(cm2[1,0]+cm2[1,1])\n",
    "print(\"Accuracy: \\t\", Accuracy_xgb)\n",
    "print(\"Sensitivity: \\t\",Sensitivity_xgb )\n",
    "print(\"Specificity: \\t\",Specificity_xgb )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Accuracy_xgb > Accuracy_adb:\n",
    "    Accuracy = Accuracy_xgb\n",
    "else:\n",
    "    Accuracy = Accuracy_adb\n",
    "if Sensitivity_xgb > Sensitivity_adb:\n",
    "    Sensitivity = Sensitivity_xgb\n",
    "else:\n",
    "    Sensitivity = Sensitivity_adb\n",
    "if Specificity_xgb > Specificity_adb:\n",
    "    Specificity = Specificity_xgb\n",
    "else:\n",
    "    Specificity = Specificity_adb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write output file\n",
    "# Assuming iris_pred is DataFrame in the required output format\n",
    "Output = [params['learning_rate'],params['n_estimators'],Accuracy.round(2),Sensitivity.round(2),Specificity.round(2)]\n",
    "output = pd.DataFrame(Ouput)\n",
    "output.to_csv('/output.csv', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
